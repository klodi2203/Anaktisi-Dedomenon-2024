{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ΒΗΜΑ 1 "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Εγκατάσταση βιβλιοθηκών"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: requests in c:\\users\\klodi\\anaconda3\\lib\\site-packages (2.31.0)\n",
      "Requirement already satisfied: beautifulsoup4 in c:\\users\\klodi\\anaconda3\\lib\\site-packages (4.12.2)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\klodi\\anaconda3\\lib\\site-packages (from requests) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\klodi\\anaconda3\\lib\\site-packages (from requests) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\klodi\\anaconda3\\lib\\site-packages (from requests) (1.26.16)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\klodi\\anaconda3\\lib\\site-packages (from requests) (2023.11.17)\n",
      "Requirement already satisfied: soupsieve>1.2 in c:\\users\\klodi\\anaconda3\\lib\\site-packages (from beautifulsoup4) (2.4)\n"
     ]
    }
   ],
   "source": [
    "!pip install requests beautifulsoup4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import βιβλιοθηκών"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import json"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Η παρακάτω συνάρτηση αναζητά άρθρα απο το wikipedia, έχοντας ως είσοδο ένα searchQuery και τον αριθμό των άρθρων που θελουμε να λάβουμε. Η συνάρτηση αυτη μόλις εκτελεστεί θα επιστρέψει το περιεχόμενο των άρθρων που βρέθηκαν και τα αποθηκεύει σε ένα αρχείο json."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Αναζήτηση για άρθρα στο Wikipedia σχετικά με: 'machine learning'...\n",
      "Βρέθηκαν 15 σύνδεσμοι άρθρων. Λήψη εγγράφων...\n",
      "Λήψη άρθρου 1: https://en.wikipedia.org/wiki/Machine_learning\n",
      "Λήψη άρθρου 2: https://en.wikipedia.org/wiki/Quantum_machine_learning\n",
      "Λήψη άρθρου 3: https://en.wikipedia.org/wiki/Neural_network_(machine_learning)\n",
      "Λήψη άρθρου 4: https://en.wikipedia.org/wiki/Attention_(machine_learning)\n",
      "Λήψη άρθρου 5: https://en.wikipedia.org/wiki/Active_learning_(machine_learning)\n",
      "Λήψη άρθρου 6: https://en.wikipedia.org/wiki/Boosting_(machine_learning)\n",
      "Λήψη άρθρου 7: https://en.wikipedia.org/wiki/Transformer_(deep_learning_architecture)\n",
      "Λήψη άρθρου 8: https://en.wikipedia.org/wiki/Adversarial_machine_learning\n",
      "Λήψη άρθρου 9: https://en.wikipedia.org/wiki/Timeline_of_machine_learning\n",
      "Λήψη άρθρου 10: https://en.wikipedia.org/wiki/Automated_machine_learning\n",
      "Λήψη άρθρου 11: https://en.wikipedia.org/wiki/Hyperparameter_(machine_learning)\n",
      "Λήψη άρθρου 12: https://en.wikipedia.org/wiki/Artificial_intelligence\n",
      "Λήψη άρθρου 13: https://en.wikipedia.org/wiki/Probabilistic_machine_learning\n",
      "Λήψη άρθρου 14: https://en.wikipedia.org/wiki/Support_vector_machine\n",
      "Λήψη άρθρου 15: https://en.wikipedia.org/wiki/Ensemble_learning\n",
      "Τα άρθρα αποθηκεύτηκαν στο αρχείο 'machine_learning_wikipedia.json'\n"
     ]
    }
   ],
   "source": [
    "def scrape_wikipedia(searchQuery, max_articles=5):\n",
    "    \n",
    "    base_url = \"https://en.wikipedia.org\"\n",
    "    search_url = f\"{base_url}/w/index.php?search={searchQuery}&title=Special:Search&fulltext=1\"\n",
    "\n",
    "    print(f\"Αναζήτηση για άρθρα στο Wikipedia σχετικά με: '{searchQuery}'...\")\n",
    "\n",
    "    response = requests.get(search_url)\n",
    "    if response.status_code != 200:\n",
    "        print(\"Δεν ήταν δυνατή η ανάκτηση της σελίδας αναζήτησης. Παρακαλώ δοκιμάστε ξανά.\")\n",
    "        return []\n",
    "\n",
    "    bSoup = BeautifulSoup(response.text, \"html.parser\")\n",
    "    articleLinks = []\n",
    "\n",
    "    search_results = bSoup.select(\".mw-search-result-heading a\")\n",
    "    for link in search_results:\n",
    "        articleLinks.append(base_url + link[\"href\"])\n",
    "        if len(articleLinks) >= max_articles:\n",
    "            break\n",
    "\n",
    "    print(f\"Βρέθηκαν {len(articleLinks)} σύνδεσμοι άρθρων. Λήψη εγγράφων...\")\n",
    "\n",
    "    articles = []\n",
    "\n",
    "    for i, url in enumerate(articleLinks):\n",
    "        print(f\"Λήψη άρθρου {i + 1}: {url}\")\n",
    "\n",
    "        response = requests.get(url)\n",
    "        if response.status_code != 200:\n",
    "            print(f\"Αποτυχία λήψης του άρθρου {i + 1}. Παράβλεψη...\")\n",
    "            continue\n",
    "\n",
    "        articleSoup = BeautifulSoup(response.text, \"html.parser\")\n",
    "\n",
    "        articleTitle = articleSoup.find(\"h1\", id=\"firstHeading\")\n",
    "        if  articleTitle:\n",
    "            title = articleTitle.text\n",
    "        else:\n",
    "            title = \"Χωρίς τίτλο\"\n",
    "\n",
    "        para = articleSoup.find_all(\"p\")\n",
    "        articleContent = \"\"  \n",
    "        for p in para:\n",
    "            articleContent += p.text + \" \"\n",
    "\n",
    "        articles.append({\n",
    "            \"title\": title,\n",
    "            \"url\": url,\n",
    "            \"content\": articleContent\n",
    "        })\n",
    "\n",
    "    fileName = searchQuery.replace(\" \", \"_\") + \"_wikipedia.json\"\n",
    "    with open(fileName, \"w\", encoding=\"utf-8\") as file:\n",
    "        json.dump(articles, file, indent=4, ensure_ascii=False)\n",
    "\n",
    "    print(f\"Τα άρθρα αποθηκεύτηκαν στο αρχείο '{fileName}'\")\n",
    "\n",
    "#---------Εκτέλεση της παραπάνω συνάρτησης-----------------------#\n",
    "\n",
    "searchQuery = input(\"Εισάγετε τo keyword για αναζήτηση άρθρων στο Wikipedia: \")\n",
    "maxArticles = int(input(\"Εισάγετε το μέγιστο πλήθος άρθρων προς λήψη: \"))\n",
    "scrape_wikipedia(searchQuery, maxArticles)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ΒΗΜΑ 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Εγκατάσταση της βιβλιοθήκης nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: nltk in c:\\users\\klodi\\anaconda3\\lib\\site-packages (3.8.1)\n",
      "Requirement already satisfied: click in c:\\users\\klodi\\anaconda3\\lib\\site-packages (from nltk) (8.0.4)\n",
      "Requirement already satisfied: joblib in c:\\users\\klodi\\anaconda3\\lib\\site-packages (from nltk) (1.2.0)\n",
      "Requirement already satisfied: regex>=2021.8.3 in c:\\users\\klodi\\anaconda3\\lib\\site-packages (from nltk) (2022.7.9)\n",
      "Requirement already satisfied: tqdm in c:\\users\\klodi\\anaconda3\\lib\\site-packages (from nltk) (4.65.0)\n",
      "Requirement already satisfied: colorama in c:\\users\\klodi\\anaconda3\\lib\\site-packages (from click->nltk) (0.4.6)\n"
     ]
    }
   ],
   "source": [
    "!pip install nltk"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import βιβλιοθηκών"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\klodi\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\klodi\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\klodi\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import PorterStemmer\n",
    "import string\n",
    "\n",
    "nltk.download('punkt')\n",
    "nltk.download('stopwords')\n",
    "nltk.download('wordnet')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "Η συνάρτηση που ακολουθεί καλείτε απο την επόμενη συνάρτηση, για την επεξεργασία του αρχείου json. Συγκεκριμένα:\n",
    "    1. Μετατρέπει το κείμενο σε πεζά γράμματα.\n",
    "    2. Αφαιρεί όλους τους χαρακτήρες εκτός από γράμματα και κενά.\n",
    "    3. Διαχωρίζει το κείμενο σε λέξεις.\n",
    "    4. Απορρίπτει τα stop words όπως the, and, κ.λπ.\n",
    "    5. Εφαρμόζει lemmatization για να μετατρέψει τις λέξεις στη βασική τους μορφή (π.χ., running → run).\n",
    "Τέλος, η συνάρτηση επιστρέφει μία λίστα, η οποία περιέχει όλες τις επεξεργασμένες λέξεις."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Αρχική πρόταση: The quick brown fox jumps over the lazy dog!\n",
      "Επεξεργασμένη πρόταση: ['quick', 'brown', 'fox', 'jump', 'lazy', 'dog']\n",
      "\n",
      "Αρχική πρόταση: Sarah's birthday party was amazing & fun!\n",
      "Επεξεργασμένη πρόταση: ['sarah', 'birthday', 'party', 'amazing', 'fun']\n",
      "\n",
      "Αρχική πρόταση: Learning Python programming is VERY interesting.\n",
      "Επεξεργασμένη πρόταση: ['learning', 'python', 'programming', 'interesting']\n",
      "\n",
      "Αρχική πρόταση: The cat's whiskers twitched while it was sleeping...\n",
      "Επεξεργασμένη πρόταση: ['cat', 'whisker', 'twitched', 'sleeping']\n",
      "\n",
      "Αρχική πρόταση: Will you be attending the meeting tomorrow?\n",
      "Επεξεργασμένη πρόταση: ['attending', 'meeting', 'tomorrow']\n"
     ]
    }
   ],
   "source": [
    "from nltk.stem import WordNetLemmatizer\n",
    "import re\n",
    "\n",
    "def processedText(words):\n",
    "   \n",
    "    words = words.lower()\n",
    "    words = re.sub(r\"[^a-zA-Z\\s]\", \" \", words)  \n",
    "    tokens = word_tokenize(words)\n",
    "    stopWords = set(stopwords.words('english'))  \n",
    "    tokens = [word for word in tokens if word not in stopWords]\n",
    "    lemmatizer = WordNetLemmatizer()\n",
    "    tokens = [lemmatizer.lemmatize(word) for word in tokens]\n",
    "    \n",
    "    return tokens\n",
    "\n",
    "#---------------Παράδειγμα εκτέλεσης της συνάρτησης------------------#\n",
    "\n",
    "def processedText_test():\n",
    "   sentences = [\n",
    "       \"The quick brown fox jumps over the lazy dog!\",\n",
    "       \"Sarah's birthday party was amazing & fun!\",\n",
    "       \"Learning Python programming is VERY interesting.\",\n",
    "       \"The cat's whiskers twitched while it was sleeping...\",\n",
    "       \"Will you be attending the meeting tomorrow?\"\n",
    "   ]\n",
    "   \n",
    "   for sentence in sentences:\n",
    "       print(\"\\nΑρχική πρόταση:\", sentence)\n",
    "       print(\"Επεξεργασμένη πρόταση:\", processedText(sentence))\n",
    "\n",
    "processedText_test()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Στόχος αυτής της συνάρτησης είναι να λάβει ως είσοδο το αρχείο json και για κάθε άρθρο να καλείται η παραπάνω συνάρτηση για την επεξεργασία του. Τέλος, τα αποτελέσματα που επιστρεφεί η processedText \n",
    "αποθηκεύονται σε ενά νέο αρχείο json, όπου πλεόν θα περιέχει όλα τα άρθρα επεξεργασμένα.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Το 'καθαρό' σύνολο δεδομένων αποθηκεύτηκε στο αρχείο: processed_machine_learning_wikipedia.json\n"
     ]
    }
   ],
   "source": [
    "def processDataset(searchQuery):\n",
    "\n",
    "    searchQuery = searchQuery.replace(\" \", \"_\").lower()\n",
    "    inFile = f\"{searchQuery}_wikipedia.json\"\n",
    "    outFile = \"processed_\" + inFile\n",
    "\n",
    "    with open(inFile, \"r\", encoding=\"utf-8\") as file:\n",
    "        data = json.load(file)\n",
    "    \n",
    "    processedData = []\n",
    "    \n",
    "    for article in data:\n",
    "        title = article.get(\"title\", \"\")\n",
    "        content = article.get(\"content\", \"\")\n",
    "        \n",
    "        processedTitle = processedText(title)\n",
    "        processedContent = processedText(content)\n",
    "        \n",
    "        processedData.append({\n",
    "            \"title\": \" \".join(processedTitle),\n",
    "            \"content\": \" \".join(processedContent),\n",
    "            \"url\": article.get(\"url\", \"\")\n",
    "        })\n",
    "    \n",
    "    with open(outFile, \"w\", encoding=\"utf-8\") as file:\n",
    "        json.dump(processedData, file, indent=4, ensure_ascii=False)\n",
    "\n",
    "    print(f\"Το 'καθαρό' σύνολο δεδομένων αποθηκεύτηκε στο αρχείο: {outFile}\")\n",
    "\n",
    "processDataset(searchQuery)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ΒΗΜΑ 3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Η συναρτηση λαμβάνει το json αρχείο που έχει παραχθεί παραπάνω και σκοπός της είναι να επιστρέψει ένα αντεστραμμένο ευρετήριο σε μορφή json. Το ευρετήριο αυτό περίεχει κάθε λέξη που εμφανίζεται στα άρθρα και πιο συγκεκριμενα εμφανιζει σε ποια άρθρα βρισκεται αυτη η λεξη , καθώς και την συχνότητα εμφάνισής της. Το τελικό ευρετήριο αποθηκεύεται σε νέο αρχείο inverted_index.json, παρέχοντας μια αποδοτική δομή για αναζητήσεις λέξεων."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Διαβάστηκαν 15 άρθρα από το αρχείο processed_machine_learning_wikipedia.json.\n",
      "Το αντεστραμμένο ευρετήριο αποθηκεύτηκε στο αρχείο inverted_index.json.\n"
     ]
    }
   ],
   "source": [
    "def invertedIndex(searchQuery):\n",
    "   \n",
    "    searchQuery = searchQuery.replace(\" \", \"_\").lower()\n",
    "    inFile = f\"processed_{searchQuery}_wikipedia.json\"\n",
    "    outFile = \"inverted_index.json\"  \n",
    "\n",
    "    try:\n",
    "        with open(inFile, \"r\", encoding=\"utf-8\") as file:\n",
    "            data = json.load(file)\n",
    "        print(f\"Διαβάστηκαν {len(data)} άρθρα από το αρχείο {inFile}.\")\n",
    "        \n",
    "        invertIndex = {}  \n",
    "\n",
    "        for doc_id, article in enumerate(data, start=1):\n",
    "            content = article.get('content', '')\n",
    "            title = article.get('title', '')\n",
    "            text = title + \" \" + content\n",
    "            \n",
    "            words = text.split() \n",
    "            \n",
    "            for word in words:\n",
    "                if word not in invertIndex:\n",
    "                    invertIndex[word] = {\"documents\": [], \"frequency\": {}}\n",
    "                \n",
    "                if doc_id not in invertIndex[word][\"documents\"]:\n",
    "                    invertIndex[word][\"documents\"].append(doc_id)\n",
    "                    invertIndex[word][\"frequency\"][doc_id] = 0  \n",
    "                \n",
    "                invertIndex[word][\"frequency\"][doc_id] += 1\n",
    "        \n",
    "        with open(outFile, \"w\", encoding=\"utf-8\") as out_file:\n",
    "            json.dump(invertIndex, out_file, indent=4, ensure_ascii=False)\n",
    "        print(f\"Το αντεστραμμένο ευρετήριο αποθηκεύτηκε στο αρχείο {outFile}.\")\n",
    "        \n",
    "    except FileNotFoundError:\n",
    "        print(\"Το αρχείο δεδομένων δεν βρέθηκε. Βεβαιωθείτε ότι υπάρχει το αρχείο JSON.\")\n",
    "\n",
    "\n",
    "invertedIndex(searchQuery)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ΒΗΜΑ 4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ερώτημα α)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Η συνάρτηση loadIndex φορτώνει το αντεστραμμένο ευρετήριο από ένα JSON αρχείο. Αρχικά, παίρνει το όνομα του αρχείου και στη συνέχεια προσπαθεί να το διαβάσει και να επιστρέψει τα δεδομένα του ως ένα dictionary. Εάν το αρχείο δεν βρεθεί, εμφανίζει ένα κατάλληλο μήνυμα σφάλματος και επιστρέφει ένα κενό dictionary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def loadIndex():\n",
    "   \n",
    "    inputFile = \"inverted_index.json\"\n",
    "    try:\n",
    "        with open(inputFile, \"r\", encoding=\"utf-8\") as file:\n",
    "            inverted_index = json.load(file)\n",
    "        print(f\"Φορτώθηκε το ευρετήριο από το αρχείο: {inputFile}\")\n",
    "        return inverted_index\n",
    "    except FileNotFoundError:\n",
    "        print(\"Το αρχείο ευρετηρίου δεν βρέθηκε.\")\n",
    "        return {}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Η συνάρτηση queryValidation ελέγχει την εγκυρότητα ενός Boolean ερωτήματος. Συγκεκριμένα, εξετάζει εάν υπάρχει ακολουθία διαδοχικών τελεστών που δεν επιτρέπεται. Εάν το ερώτημα δεν πληροί τους παρακάτω κανόνες επιστρέφει False , αλλιώς επιστρέφει True."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def queryValidation(terms):\n",
    "\n",
    "    logicalOp = {'and', 'or', 'not'}\n",
    "    \n",
    "    if terms[0].lower() in {'and', 'or'}:\n",
    "        return False, \"Το ερώτημα δεν μπορεί να ξεκινά με AND ή OR\"\n",
    "    \n",
    "    if terms[-1].lower() in logicalOp:\n",
    "        return False, \"Το ερώτημα δεν μπορεί να τελειώνει με τελεστή\"\n",
    "    \n",
    "    for i in range(len(terms) - 1):\n",
    "        if terms[i].lower() in logicalOp and terms[i+1].lower() in logicalOp - {'not'}:\n",
    "            return False, \"Μη έγκυρη ακολουθία τελεστών\"\n",
    "        \n",
    "    for i in range(len(terms) - 1):\n",
    "        if terms[i].lower() == 'not' and terms[i+1].lower() in logicalOp:\n",
    "            return False, \"Το NOT δεν μπορεί να ακολουθείται από τελεστή\"\n",
    "        \n",
    "    return True, \"\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Η συνάρτηση processQuery επεξεργάζεται Boolean queries για την ανάκτηση εγγράφων από το αντεστραμμένο ευρετήριο. Αναλύει το query, εφαρμόζει τους τελεστές AND, OR, NOT και επιστρέφει τα σχετικά έγγραφα. Εάν το ερώτημα είναι άκυρο, επιστρέφει κενό σύνολο."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Αρχικό ερώτημα: machine learning\n",
      "Αναζητούμενες λέξεις: machine, learning\n",
      "Έγγραφα: [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15]\n",
      "\n",
      "Αρχικό ερώτημα: deep neural\n",
      "Αναζητούμενες λέξεις: deep, neural\n",
      "Έγγραφα: [1, 2, 3, 4, 7, 8, 10, 11, 12, 13, 15]\n",
      "\n",
      "Αρχικό ερώτημα: artificial intelligence\n",
      "Αναζητούμενες λέξεις: artificial, intelligence\n",
      "Έγγραφα: [1, 2, 3, 10, 12, 13]\n",
      "\n",
      "Αρχικό ερώτημα: data mining\n",
      "Αναζητούμενες λέξεις: data, mining\n",
      "Έγγραφα: [1, 12, 13]\n",
      "\n",
      "Αρχικό ερώτημα: machine and learning\n",
      "Αναζητούμενες λέξεις: machine, learning\n",
      "Έγγραφα: [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15]\n",
      "\n",
      "Αρχικό ερώτημα: deep or neural\n",
      "Αναζητούμενες λέξεις: deep, neural\n",
      "Έγγραφα: [1, 2, 3, 4, 6, 7, 8, 10, 11, 12, 13, 15]\n",
      "\n",
      "Αρχικό ερώτημα: machine and not deep\n",
      "Αναζητούμενες λέξεις: machine, deep\n",
      "Έγγραφα: [5, 6, 9, 14]\n",
      "\n",
      "Αρχικό ερώτημα: neural networks\n",
      "Αναζητούμενες λέξεις: neural, networks\n",
      "Έγγραφα: []\n",
      "\n",
      "Αρχικό ερώτημα: supervised learning\n",
      "Αναζητούμενες λέξεις: supervised, learning\n",
      "Έγγραφα: [1, 2, 3, 5, 6, 7, 8, 12, 13, 14, 15]\n",
      "\n",
      "Αρχικό ερώτημα: reinforcement learning\n",
      "Αναζητούμενες λέξεις: reinforcement, learning\n",
      "Έγγραφα: [1, 2, 3, 7, 8, 11, 12, 13]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "def processTerm(term, docList, inverted_index, finalResult, logicalOp=None):\n",
    "\n",
    "    documents = set(inverted_index.get(term, {}).get(\"documents\", []))\n",
    "    \n",
    "    if logicalOp == \"not\":\n",
    "        documents = docList.difference(documents)\n",
    "    if finalResult is None:\n",
    "        return documents\n",
    "    elif logicalOp == \"and\":\n",
    "        return finalResult.intersection(documents)\n",
    "    elif logicalOp == \"or\":\n",
    "        return finalResult.union(documents)\n",
    "    else: \n",
    "        return finalResult.intersection(documents)\n",
    "\n",
    "def processQuery(query, inverted_index):\n",
    "    terms = query.lower().split()\n",
    "    valid, errorMess = queryValidation(terms)\n",
    "    if not valid:\n",
    "        print(f\"Σφάλμα: {errorMess}\")\n",
    "        return set()\n",
    "    \n",
    "    print(f\"Αρχικό ερώτημα: {query}\")\n",
    "    print(f\"Αναζητούμενες λέξεις: {', '.join([term for term in terms if term not in ['and', 'or', 'not']])}\")\n",
    "\n",
    "    docList = set()\n",
    "    for docs in inverted_index.values():\n",
    "        docList.update(docs.get(\"documents\", []))\n",
    "\n",
    "    results = None\n",
    "    i = 0\n",
    "\n",
    "    while i < len(terms):\n",
    "        term = terms[i]\n",
    "\n",
    "        if term == \"not\":\n",
    "            i += 1\n",
    "            if i < len(terms):\n",
    "                results = processTerm(terms[i], docList, inverted_index, results, logicalOp=\"not\")\n",
    "            i += 1\n",
    "\n",
    "        elif term == \"and\":\n",
    "            i += 1\n",
    "            if i < len(terms):\n",
    "                if terms[i] == \"not\":\n",
    "                    i += 1\n",
    "                    if i < len(terms):\n",
    "                        results = processTerm(terms[i], docList, inverted_index, results, logicalOp=\"not\")\n",
    "                else:\n",
    "                    results = processTerm(terms[i], docList, inverted_index, results, logicalOp=\"and\")\n",
    "            i += 1\n",
    "\n",
    "        elif term == \"or\":\n",
    "            i += 1\n",
    "            if i < len(terms):\n",
    "                if terms[i] == \"not\":\n",
    "                    i += 1\n",
    "                    if i < len(terms):\n",
    "                        results = processTerm(terms[i], docList, inverted_index, results, logicalOp=\"not\")\n",
    "                else:\n",
    "                    results = processTerm(terms[i], docList, inverted_index, results, logicalOp=\"or\")\n",
    "            i += 1\n",
    "\n",
    "        else:\n",
    "            results = processTerm(term, docList, inverted_index, results)\n",
    "            i += 1\n",
    "\n",
    "    return results if results is not None else set()\n",
    "\n",
    "\n",
    "#------------Παράδειγμα εκτέλεσης συνάρτησης-------------#\n",
    "\n",
    "def testQueries():\n",
    "    queries = [\n",
    "        \"machine learning\",\n",
    "        \"deep neural\",\n",
    "        \"artificial intelligence\",\n",
    "        \"data mining\",\n",
    "        \"machine and learning\",\n",
    "        \"deep or neural\",\n",
    "        \"machine and not deep\",\n",
    "        \"neural networks\",\n",
    "        \"supervised learning\",\n",
    "        \"reinforcement learning\"\n",
    "    ]\n",
    "    \n",
    "    for query in queries:\n",
    "        with open(\"inverted_index.json\", \"r\", encoding=\"utf-8\") as file:\n",
    "            inverted_index = json.load(file)\n",
    "        results = processQuery(query, inverted_index)\n",
    "        print(f\"Έγγραφα: {sorted(list(results))}\\n\")\n",
    "\n",
    "testQueries()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ΕΡΩΤΗΜΑ Β"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "Η συνάρτηση prepareDocuments επεξεργάζεται το αντεστραμμένο ευρετήριο για να δημιουργήσει το περιεχόμενο των εγγράφων σε κατάλληλη μορφή για τον υπολογισμό του TF-IDF. Ομαδοποιεί τους όρους κάθε εγγράφου, τους ενώνει σε μία συμβολοσειρά και επιστρέφει λίστες με τα κείμενα των εγγράφων και τα αντίστοιχα IDs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "\n",
    "def prepareDocuments(inverted_index):\n",
    "    documents = {}\n",
    "    \n",
    "    for term, data in inverted_index.items():\n",
    "        for docId in data.get(\"documents\", []):\n",
    "            if docId not in documents:\n",
    "                documents[docId] = []\n",
    "\n",
    "            Freq = data[\"frequency\"].get(str(docId), 0)  \n",
    "            documents[docId].extend([term] * Freq)\n",
    "    \n",
    "    documentTexts = [\" \".join(terms) for docId, terms in sorted(documents.items())]\n",
    "    documentIds = [docId for docId, _ in sorted(documents.items())]\n",
    "    \n",
    "    return documentTexts, documentIds"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Η συνάρτηση computeTfidf υπολογίζει το TF-IDF για μια λίστα εγγράφων. Επιστρέφει τον πίνακα TF-IDF, τα χαρακτηριστικά και το ίδιο το αντικείμενο vectorizer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def computeTfidf(documents):\n",
    "    \n",
    "    vectorizer = TfidfVectorizer()\n",
    "    tableTfidf = vectorizer.fit_transform(documents)\n",
    "    newNames = vectorizer.get_feature_names_out()\n",
    "    return tableTfidf, newNames, vectorizer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Η συνάρτηση rank_documents κατατάσσει έγγραφα με βάση τη συνάφεια τους με ένα ερώτημα. Μετατρέπει το ερώτημα σε διάνυσμα TF-IDF, υπολογίζει το cosine similarity με τα έγγραφα και τα επιστρέφει ταξινομημένα κατά βαθμολογία."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_score(item):\n",
    "    return item[1]\n",
    "\n",
    "def rankDocuments(query, TableTfidf, vectorizer, doc_ids):\n",
    "\n",
    "    tfidfQuery = vectorizer.transform([query])\n",
    "    cos = cosine_similarity(tfidfQuery, TableTfidf).flatten()\n",
    "    documentScores = [(doc_id, score) for doc_id, score in zip(doc_ids, cos)]\n",
    "    rankedDocuments = sorted(documentScores, key=get_score, reverse=True)\n",
    "    \n",
    "    return rankedDocuments"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Εγκατάσταση της rank-bm25"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: rank-bm25 in c:\\users\\klodi\\anaconda3\\lib\\site-packages (0.2.2)\n",
      "Requirement already satisfied: numpy in c:\\users\\klodi\\anaconda3\\lib\\site-packages (from rank-bm25) (1.24.3)\n"
     ]
    }
   ],
   "source": [
    "!pip install rank-bm25\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "Η συνάρτηση rankDocuments_bm25 βρίσκει ποια έγγραφα ταιριάζουν περισσότερο με ένα ερώτημα, χρησιμοποιώντας τον αλγόριθμο BM25. Χωρίζει τα έγγραφα και το ερώτημα σε λέξεις, υπολογίζει βαθμολογίες για κάθε έγγραφο και επιστρέφει τα έγγραφα ταξινομημένα."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "from rank_bm25 import BM25Okapi\n",
    "\n",
    "def rankDocuments_bm25(query, documents):\n",
    " \n",
    "    tokenizedDoc = [doc.split() for doc in documents]\n",
    "    bm25 = BM25Okapi(tokenizedDoc)\n",
    "    tokenizedQuery = query.split()\n",
    "    scores = bm25.get_scores(tokenizedQuery)\n",
    "    rankedResults = sorted(enumerate(scores), key=get_score, reverse=True)\n",
    "\n",
    "    return rankedResults\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Η συνάρτηση computeVsm μετατρέπει τα κείμενα και το ερώτημα σε διανύσματα χρησιμοποιώντας το CountVectorizer, κανονικοποιεί τα διανύσματα, και υπολογίζει την ομοιότητα συνημίτονου μεταξύ του ερωτήματος και των κειμένων για να επιστρέψει τα έγγραφα ταξινομημένα με βάση τη σχετικότητά τους."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.preprocessing import normalize\n",
    "import numpy as np\n",
    "\n",
    "def computeVsm(query, documents, document_ids):\n",
    "    vectorizer = CountVectorizer()\n",
    "    tablesDoc = vectorizer.fit_transform(documents)\n",
    "    tableQuery = vectorizer.transform([query])\n",
    "    normalizedDocs = normalize(tablesDoc)\n",
    "    normalizedQuery = normalize(tableQuery)\n",
    "    similarities = (normalizedQuery @ normalizedDocs.T).toarray().flatten()\n",
    "    rankedResults = sorted(zip(document_ids, similarities), key=lambda x: x[1], reverse=True)\n",
    "    \n",
    "    return rankedResults "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Η main φορτώνει το ευρετήριο και τα έγγραφα, και στη συνέχεια προσφέρει ένα μενού στον χρήστη για να μπορεί να επιλέξει ανάμεσα στους διαφορετικούς αλγορίθμους που έχουμε υλοποιήσει. Ο χρήστης μπορεί να εισάγει ένα ερώτημα και να λάβει τα αντίστοιχα αποτελέσματα ταξινομημένα με βάση τη σχετικότητα."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Φορτώθηκε το ευρετήριο από το αρχείο: inverted_index.json\n",
      "\n",
      "Επιλέξτε αλγόριθμο αναζήτησης:\n",
      "1: Boolean Retrieval\n",
      "2: TF-IDF Ranking\n",
      "3: BM25 Ranking\n",
      "4: Vector Space Model (VSM)\n",
      "0: Έξοδος\n",
      "Αρχικό ερώτημα: machine learning\n",
      "Αναζητούμενες λέξεις: machine, learning\n",
      "\n",
      "Αποτελέσματα Boolean Retrieval:\n",
      "[1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15]\n",
      "\n",
      "Επιλέξτε αλγόριθμο αναζήτησης:\n",
      "1: Boolean Retrieval\n",
      "2: TF-IDF Ranking\n",
      "3: BM25 Ranking\n",
      "4: Vector Space Model (VSM)\n",
      "0: Έξοδος\n",
      "Μη έγκυρη επιλογή. Προσπαθήστε ξανά.\n",
      "\n",
      "Επιλέξτε αλγόριθμο αναζήτησης:\n",
      "1: Boolean Retrieval\n",
      "2: TF-IDF Ranking\n",
      "3: BM25 Ranking\n",
      "4: Vector Space Model (VSM)\n",
      "0: Έξοδος\n",
      "\n",
      "Αποτελέσματα BM25 Ranking:\n",
      "Έγγραφο: 1                    Βαθμολογία: 1.8696\n",
      "Έγγραφο: 10                   Βαθμολογία: 1.8572\n",
      "Έγγραφο: 2                    Βαθμολογία: 1.8537\n",
      "Έγγραφο: 8                    Βαθμολογία: 1.8303\n",
      "Έγγραφο: 5                    Βαθμολογία: 1.8081\n",
      "Έγγραφο: 12                   Βαθμολογία: 1.8021\n",
      "Έγγραφο: 13                   Βαθμολογία: 1.8021\n",
      "Έγγραφο: 3                    Βαθμολογία: 1.7832\n",
      "Έγγραφο: 11                   Βαθμολογία: 1.7623\n",
      "Έγγραφο: 6                    Βαθμολογία: 1.7344\n",
      "\n",
      "Επιλέξτε αλγόριθμο αναζήτησης:\n",
      "1: Boolean Retrieval\n",
      "2: TF-IDF Ranking\n",
      "3: BM25 Ranking\n",
      "4: Vector Space Model (VSM)\n",
      "0: Έξοδος\n",
      "\n",
      "Αποτελέσματα Vector Space Model (VSM):\n",
      "Έγγραφο: 10                   Βαθμολογία: 0.7906\n",
      "Έγγραφο: 9                    Βαθμολογία: 0.7500\n",
      "Έγγραφο: 1                    Βαθμολογία: 0.6782\n",
      "Έγγραφο: 5                    Βαθμολογία: 0.6031\n",
      "Έγγραφο: 2                    Βαθμολογία: 0.3642\n",
      "Έγγραφο: 8                    Βαθμολογία: 0.3110\n",
      "Έγγραφο: 3                    Βαθμολογία: 0.2857\n",
      "Έγγραφο: 11                   Βαθμολογία: 0.2640\n",
      "Έγγραφο: 12                   Βαθμολογία: 0.2337\n",
      "Έγγραφο: 13                   Βαθμολογία: 0.2337\n",
      "\n",
      "Επιλέξτε αλγόριθμο αναζήτησης:\n",
      "1: Boolean Retrieval\n",
      "2: TF-IDF Ranking\n",
      "3: BM25 Ranking\n",
      "4: Vector Space Model (VSM)\n",
      "0: Έξοδος\n",
      "Αρχικό ερώτημα: suggests\n",
      "Αναζητούμενες λέξεις: suggests\n",
      "\n",
      "Αποτελέσματα Boolean Retrieval:\n",
      "[2, 4, 8, 12, 13]\n",
      "\n",
      "Επιλέξτε αλγόριθμο αναζήτησης:\n",
      "1: Boolean Retrieval\n",
      "2: TF-IDF Ranking\n",
      "3: BM25 Ranking\n",
      "4: Vector Space Model (VSM)\n",
      "0: Έξοδος\n",
      "Αρχικό ερώτημα: machine and not suggests\n",
      "Αναζητούμενες λέξεις: machine, suggests\n",
      "\n",
      "Αποτελέσματα Boolean Retrieval:\n",
      "[1, 3, 5, 6, 7, 9, 10, 11, 14, 15]\n",
      "\n",
      "Επιλέξτε αλγόριθμο αναζήτησης:\n",
      "1: Boolean Retrieval\n",
      "2: TF-IDF Ranking\n",
      "3: BM25 Ranking\n",
      "4: Vector Space Model (VSM)\n",
      "0: Έξοδος\n",
      "Τερματισμός προγράμματος.\n"
     ]
    }
   ],
   "source": [
    "def menu():\n",
    "\n",
    "    invertedIndex = loadIndex()\n",
    "    docstexts, docIds = prepareDocuments(invertedIndex)\n",
    "\n",
    "    while True:\n",
    "        print(\"\\nΕπιλέξτε αλγόριθμο αναζήτησης:\")\n",
    "        print(\"1: Boolean Retrieval\")\n",
    "        print(\"2: TF-IDF Ranking\")\n",
    "        print(\"3: BM25 Ranking\")\n",
    "        print(\"4: Vector Space Model (VSM)\")\n",
    "        print(\"0: Έξοδος\")\n",
    "        choice = input(\"Επιλογή: \")\n",
    "\n",
    "        if choice == \"0\":\n",
    "            print(\"Τερματισμός προγράμματος.\")\n",
    "            break\n",
    "\n",
    "        query = input(\"\\nΕισάγετε το ερώτημά σας: \")\n",
    "\n",
    "        if choice == \"1\":\n",
    "            results = processQuery(query, invertedIndex)\n",
    "            print(\"\\nΑποτελέσματα Boolean Retrieval:\")\n",
    "            print(sorted(results))\n",
    "\n",
    "        elif choice == \"2\":\n",
    "            tableTfidf, newNames, vectorizer = computeTfidf(docstexts)\n",
    "            rankedResults = rankDocuments(query, tableTfidf, vectorizer, docIds)\n",
    "            print(\"\\nΑποτελέσματα TF-IDF Ranking:\")\n",
    "            for id, score in rankedResults[:10]:\n",
    "                if score > 0:\n",
    "                    print(f\"Έγγραφο: {id:<20} Βαθμολογία: {score:.4f}\")\n",
    "\n",
    "        elif choice == \"3\":\n",
    "            rankedResults = rankDocuments_bm25(query, docstexts)\n",
    "            print(\"\\nΑποτελέσματα BM25 Ranking:\")\n",
    "            for dx, score in rankedResults[:10]:\n",
    "                if score > 0:\n",
    "                    print(f\"Έγγραφο: {docIds[dx]:<20} Βαθμολογία: {score:.4f}\")\n",
    "\n",
    "        elif choice == \"4\":\n",
    "            rankedResults = computeVsm(query, docstexts, docIds)\n",
    "            print(\"\\nΑποτελέσματα Vector Space Model (VSM):\")\n",
    "            for id, score in rankedResults[:10]:\n",
    "                if score > 0:\n",
    "                    print(f\"Έγγραφο: {id:<20} Βαθμολογία: {score:.4f}\")\n",
    "\n",
    "        else:\n",
    "            print(\"Μη έγκυρη επιλογή. Προσπαθήστε ξανά.\")\n",
    "\n",
    "menu()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ΒΗΜΑ 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Δυαδικός πίνακας εγγράφων:\n",
      "Έγγραφα:  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15\n",
      "--------------------------------------------------\n",
      "machine learning      1  1  1  1  1  1  1  1  1  1  1  1  1  1  1\n",
      "artificial intellige  1  1  1  0  0  0  0  0  1  1  0  0  0  0  1\n",
      "statistical analysis  1  0  1  1  0  0  0  0  1  1  0  0  1  1  0\n",
      "natural language pro  1  1  1  0  1  0  1  0  1  1  0  0  0  0  0\n",
      "computer vision       1  0  1  1  1  0  1  0  1  1  1  0  0  0  0\n",
      "speech recognition    1  0  1  1  0  0  1  0  1  1  0  0  0  1  0\n",
      "predictive analytics  1  0  0  0  0  0  0  0  1  1  0  0  0  0  0\n",
      "data mining           1  0  0  0  0  0  0  0  1  1  0  0  0  0  0\n",
      "unsupervised learnin  1  1  1  0  0  0  0  0  1  1  1  0  1  1  0\n",
      "algorithm optimizati  1  1  1  1  0  0  1  0  1  1  1  1  1  0  1\n",
      "mathematical model    1  1  0  0  0  0  0  0  1  1  0  0  0  0  0\n",
      "machine learning AND  1  1  1  0  0  0  0  0  1  1  0  0  0  0  1\n",
      "deep learning NOT ne  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
      "statistical OR mathe  1  1  1  1  0  0  1  0  1  1  0  0  1  1  0\n",
      "computer vision AND   1  0  1  1  1  0  1  0  1  1  0  0  0  0  0\n",
      "model performance     1  1  1  0  0  0  1  0  1  1  1  1  1  1  1\n",
      "artificial intellige  1  1  1  0  0  0  0  0  1  1  0  0  0  0  1\n",
      "machine learning AND  0  0  0  0  0  0  0  0  0  0  0  0  1  0  0\n",
      "neural network AND o  1  1  1  1  0  0  1  0  1  1  1  1  0  0  1\n",
      "\n",
      "Ερώτημα: machine learning\n",
      "Ακρίβεια: 1.000\n",
      "Ανάκληση: 1.000\n",
      "F1 Score: 1.000\n",
      "Ανακτημένα έγγραφα: 15\n",
      "Σχετικά έγγραφα: 15\n",
      "\n",
      "Ερώτημα: artificial intelligence\n",
      "Ακρίβεια: 0.400\n",
      "Ανάκληση: 1.000\n",
      "F1 Score: 0.571\n",
      "Ανακτημένα έγγραφα: 6\n",
      "Σχετικά έγγραφα: 6\n",
      "\n",
      "Ερώτημα: statistical analysis\n",
      "Ακρίβεια: 0.467\n",
      "Ανάκληση: 1.000\n",
      "F1 Score: 0.636\n",
      "Ανακτημένα έγγραφα: 7\n",
      "Σχετικά έγγραφα: 7\n",
      "\n",
      "Ερώτημα: natural language processing\n",
      "Ακρίβεια: 0.467\n",
      "Ανάκληση: 1.000\n",
      "F1 Score: 0.636\n",
      "Ανακτημένα έγγραφα: 7\n",
      "Σχετικά έγγραφα: 7\n",
      "\n",
      "Ερώτημα: computer vision\n",
      "Ακρίβεια: 0.533\n",
      "Ανάκληση: 1.000\n",
      "F1 Score: 0.696\n",
      "Ανακτημένα έγγραφα: 8\n",
      "Σχετικά έγγραφα: 8\n",
      "\n",
      "Ερώτημα: speech recognition\n",
      "Ακρίβεια: 0.467\n",
      "Ανάκληση: 1.000\n",
      "F1 Score: 0.636\n",
      "Ανακτημένα έγγραφα: 7\n",
      "Σχετικά έγγραφα: 7\n",
      "\n",
      "Ερώτημα: predictive analytics\n",
      "Ακρίβεια: 0.200\n",
      "Ανάκληση: 1.000\n",
      "F1 Score: 0.333\n",
      "Ανακτημένα έγγραφα: 3\n",
      "Σχετικά έγγραφα: 3\n",
      "\n",
      "Ερώτημα: data mining\n",
      "Ακρίβεια: 0.200\n",
      "Ανάκληση: 1.000\n",
      "F1 Score: 0.333\n",
      "Ανακτημένα έγγραφα: 3\n",
      "Σχετικά έγγραφα: 3\n",
      "\n",
      "Ερώτημα: unsupervised learning\n",
      "Ακρίβεια: 0.533\n",
      "Ανάκληση: 1.000\n",
      "F1 Score: 0.696\n",
      "Ανακτημένα έγγραφα: 8\n",
      "Σχετικά έγγραφα: 8\n",
      "\n",
      "Ερώτημα: algorithm optimization\n",
      "Ακρίβεια: 0.733\n",
      "Ανάκληση: 1.000\n",
      "F1 Score: 0.846\n",
      "Ανακτημένα έγγραφα: 11\n",
      "Σχετικά έγγραφα: 11\n",
      "\n",
      "Ερώτημα: mathematical model\n",
      "Ακρίβεια: 0.267\n",
      "Ανάκληση: 1.000\n",
      "F1 Score: 0.421\n",
      "Ανακτημένα έγγραφα: 4\n",
      "Σχετικά έγγραφα: 4\n",
      "\n",
      "Ερώτημα: machine learning AND artificial intelligence\n",
      "Ακρίβεια: 0.400\n",
      "Ανάκληση: 1.000\n",
      "F1 Score: 0.571\n",
      "Ανακτημένα έγγραφα: 6\n",
      "Σχετικά έγγραφα: 6\n",
      "\n",
      "Ερώτημα: deep learning NOT neural networks\n",
      "Ακρίβεια: 0.000\n",
      "Ανάκληση: 0.000\n",
      "F1 Score: 0.000\n",
      "Ανακτημένα έγγραφα: 0\n",
      "Σχετικά έγγραφα: 0\n",
      "\n",
      "Ερώτημα: statistical OR mathematical\n",
      "Ακρίβεια: 0.600\n",
      "Ανάκληση: 1.000\n",
      "F1 Score: 0.750\n",
      "Ανακτημένα έγγραφα: 9\n",
      "Σχετικά έγγραφα: 9\n",
      "\n",
      "Ερώτημα: computer vision AND deep learning\n",
      "Ακρίβεια: 0.467\n",
      "Ανάκληση: 1.000\n",
      "F1 Score: 0.636\n",
      "Ανακτημένα έγγραφα: 7\n",
      "Σχετικά έγγραφα: 7\n",
      "\n",
      "Ερώτημα: model performance\n",
      "Ακρίβεια: 0.733\n",
      "Ανάκληση: 1.000\n",
      "F1 Score: 0.846\n",
      "Ανακτημένα έγγραφα: 11\n",
      "Σχετικά έγγραφα: 11\n",
      "\n",
      "Ερώτημα: artificial intelligence method\n",
      "Ακρίβεια: 0.400\n",
      "Ανάκληση: 1.000\n",
      "F1 Score: 0.571\n",
      "Ανακτημένα έγγραφα: 6\n",
      "Σχετικά έγγραφα: 6\n",
      "\n",
      "Ερώτημα: machine learning AND statistical NOT deep\n",
      "Ακρίβεια: 0.067\n",
      "Ανάκληση: 1.000\n",
      "F1 Score: 0.125\n",
      "Ανακτημένα έγγραφα: 1\n",
      "Σχετικά έγγραφα: 1\n",
      "\n",
      "Ερώτημα: neural network AND optimization\n",
      "Ακρίβεια: 0.667\n",
      "Ανάκληση: 1.000\n",
      "F1 Score: 0.800\n",
      "Ανακτημένα έγγραφα: 10\n",
      "Σχετικά έγγραφα: 10\n",
      "\n",
      "Συνολική απόοδση συστήματος:\n",
      "------------------------------\n",
      "Μέση ακρίβεια: 0.453\n",
      "Μέση ανάκληση: 0.947\n",
      "Μέσο F1 Score: 0.585\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.metrics import precision_score, recall_score, f1_score, average_precision_score\n",
    "\n",
    "queries = [\n",
    "    \"machine learning\",\n",
    "    \"artificial intelligence\", \n",
    "    \"statistical analysis\",\n",
    "    \"natural language processing\",\n",
    "    \"computer vision\",\n",
    "    \"speech recognition\", \n",
    "    \"predictive analytics\",\n",
    "    \"data mining\",\n",
    "    \"unsupervised learning\",\n",
    "    \"algorithm optimization\",\n",
    "    \"mathematical model\",\n",
    "    \"machine learning AND artificial intelligence\",\n",
    "    \"deep learning NOT neural networks\",\n",
    "    \"statistical OR mathematical\",\n",
    "    \"computer vision AND deep learning\",\n",
    "    \"model performance\",\n",
    "    \"artificial intelligence method\",\n",
    "    \"machine learning AND statistical NOT deep\",\n",
    "    \"neural network AND optimization\"\n",
    "]\n",
    "\n",
    "results = [\n",
    "    [1,2,3,4,5,6,7,8,9,10,11,12,13,14,15],\n",
    "    [1,2,3,9,10,15],\n",
    "    [1,3,4,9,10,13,14],\n",
    "    [1,2,3,5,7,9,10],\n",
    "    [1,3,4,5,7,9,10,11],\n",
    "    [1,3,4,7,9,10,14],\n",
    "    [1,9,10],\n",
    "    [1,9,10],\n",
    "    [1,2,3,9,10,11,13,14],\n",
    "    [1,2,3,4,7,9,10,11,12,13,15],\n",
    "    [1,2,9,10],\n",
    "    [1,2,3,9,10,15],\n",
    "    [],\n",
    "    [1,2,3,4,7,9,10,13,14],\n",
    "    [1,3,4,5,7,9,10],\n",
    "    [1,2,3,7,9,10,11,12,13,14,15],\n",
    "    [1,2,3,9,10,15],\n",
    "    [13],\n",
    "    [1,2,3,4,7,9,10,11,12,15]\n",
    "]\n",
    "\n",
    "def binaryMatrix():\n",
    "    matrix = np.zeros((len(queries), 15))\n",
    "    for i, result in enumerate(results):\n",
    "        for doc_id in result:\n",
    "            matrix[i][doc_id-1] = 1\n",
    "    return matrix\n",
    "\n",
    "def calculateMetrics(matrix):\n",
    "    query_metrics = []\n",
    "    \n",
    "    for i, query in enumerate(queries):\n",
    "        relevant_docs = np.where(matrix[i] == 1)[0]\n",
    "        total_docs = len(matrix[i])\n",
    "        retrieved_docs = len(results[i])\n",
    "        \n",
    "        if retrieved_docs == 0:\n",
    "            precision = 0\n",
    "            recall = 0\n",
    "            f1 = 0\n",
    "        else:\n",
    "            precision = len(relevant_docs) / total_docs\n",
    "            recall = len(relevant_docs) / retrieved_docs\n",
    "            f1 = 2 * (precision * recall) / (precision + recall) if (precision + recall) > 0 else 0\n",
    "            \n",
    "        query_metrics.append({\n",
    "            'query': query,\n",
    "            'precision': precision,\n",
    "            'recall': recall,\n",
    "            'f1': f1,\n",
    "            'retrieved_docs': retrieved_docs,\n",
    "            'relevant_docs': len(relevant_docs)\n",
    "        })\n",
    "    \n",
    "    return query_metrics\n",
    "\n",
    "def printResults(matrix, query_metrics):\n",
    "    print(\"\\nΔυαδικός πίνακας εγγράφων:\")\n",
    "    print(\"Έγγραφα:  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15\")\n",
    "    print(\"-\" * 50)\n",
    "    for i, query in enumerate(queries):\n",
    "        row = ' '.join(f'{int(x):2}' for x in matrix[i])\n",
    "        print(f\"{query[:20]:<20} {row}\")\n",
    "    \n",
    "\n",
    "    for m in query_metrics:\n",
    "        print(f\"\\nΕρώτημα: {m['query']}\")\n",
    "        print(f\"Ακρίβεια: {m['precision']:.3f}\")\n",
    "        print(f\"Ανάκληση: {m['recall']:.3f}\")\n",
    "        print(f\"F1 Score: {m['f1']:.3f}\")\n",
    "        print(f\"Ανακτημένα έγγραφα: {m['retrieved_docs']}\")\n",
    "        print(f\"Σχετικά έγγραφα: {m['relevant_docs']}\")\n",
    "    \n",
    "    avg_precision = np.mean([m['precision'] for m in query_metrics])\n",
    "    avg_recall = np.mean([m['recall'] for m in query_metrics])\n",
    "    avg_f1 = np.mean([m['f1'] for m in query_metrics])\n",
    "    \n",
    "    print(\"\\nΣυνολική απόοδση συστήματος:\")\n",
    "    print(\"-\" * 30)\n",
    "    print(f\"Μέση ακρίβεια: {avg_precision:.3f}\")\n",
    "    print(f\"Μέση ανάκληση: {avg_recall:.3f}\")\n",
    "    print(f\"Μέσο F1 Score: {avg_f1:.3f}\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "\n",
    "    relevance_matrix = binaryMatrix()\n",
    "    query_metrics = calculateMetrics(relevance_matrix)\n",
    "    printResults(relevance_matrix, query_metrics)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
